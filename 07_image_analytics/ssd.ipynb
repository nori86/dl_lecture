{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ssd.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"-L1JBdqy9wiv","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","\n","\n","class BBoxUtility(object):\n","    \"\"\"Utility class to do some stuff with bounding boxes and priors.\n","    # Arguments\n","        num_classes: Number of classes including background.\n","        priors: Priors and variances, numpy tensor of shape (num_priors, 8),\n","            priors[i] = [xmin, ymin, xmax, ymax, varxc, varyc, varw, varh].\n","        overlap_threshold: Threshold to assign box to a prior.\n","        nms_thresh: Nms threshold.\n","        top_k: Number of total bboxes to be kept per image after nms step.\n","    # References\n","        https://arxiv.org/abs/1512.02325\n","    \"\"\"\n","    # TODO add setter methods for nms_thresh and top_K\n","    def __init__(self, num_classes, priors=None, overlap_threshold=0.5,\n","                 nms_thresh=0.45, top_k=400):\n","        self.num_classes = num_classes\n","        self.priors = priors\n","        self.num_priors = 0 if priors is None else len(priors)\n","        self.overlap_threshold = overlap_threshold\n","        self._nms_thresh = nms_thresh\n","        self._top_k = top_k\n","        self.boxes = tf.placeholder(dtype='float32', shape=(None, 4))\n","        self.scores = tf.placeholder(dtype='float32', shape=(None,))\n","        self.nms = tf.image.non_max_suppression(self.boxes, self.scores,\n","                                                self._top_k,\n","                                                iou_threshold=self._nms_thresh)\n","        self.sess = tf.Session(config=tf.ConfigProto(device_count={'GPU': 0}))\n","\n","    @property\n","    def nms_thresh(self):\n","        return self._nms_thresh\n","\n","    @nms_thresh.setter\n","    def nms_thresh(self, value):\n","        self._nms_thresh = value\n","        self.nms = tf.image.non_max_suppression(self.boxes, self.scores,\n","                                                self._top_k,\n","                                                iou_threshold=self._nms_thresh)\n","\n","    @property\n","    def top_k(self):\n","        return self._top_k\n","\n","    @top_k.setter\n","    def top_k(self, value):\n","        self._top_k = value\n","        self.nms = tf.image.non_max_suppression(self.boxes, self.scores,\n","                                                self._top_k,\n","                                                iou_threshold=self._nms_thresh)\n","\n","    def iou(self, box):\n","        \"\"\"Compute intersection over union for the box with all priors.\n","        # Arguments\n","            box: Box, numpy tensor of shape (4,).\n","        # Return\n","            iou: Intersection over union,\n","                numpy tensor of shape (num_priors).\n","        \"\"\"\n","        # compute intersection\n","        inter_upleft = np.maximum(self.priors[:, :2], box[:2])\n","        inter_botright = np.minimum(self.priors[:, 2:4], box[2:])\n","        inter_wh = inter_botright - inter_upleft\n","        inter_wh = np.maximum(inter_wh, 0)\n","        inter = inter_wh[:, 0] * inter_wh[:, 1]\n","        # compute union\n","        area_pred = (box[2] - box[0]) * (box[3] - box[1])\n","        area_gt = (self.priors[:, 2] - self.priors[:, 0])\n","        area_gt *= (self.priors[:, 3] - self.priors[:, 1])\n","        union = area_pred + area_gt - inter\n","        # compute iou\n","        iou = inter / union\n","        return iou\n","\n","    def encode_box(self, box, return_iou=True):\n","        \"\"\"Encode box for training, do it only for assigned priors.\n","        # Arguments\n","            box: Box, numpy tensor of shape (4,).\n","            return_iou: Whether to concat iou to encoded values.\n","        # Return\n","            encoded_box: Tensor with encoded box\n","                numpy tensor of shape (num_priors, 4 + int(return_iou)).\n","        \"\"\"\n","        iou = self.iou(box)\n","        encoded_box = np.zeros((self.num_priors, 4 + return_iou))\n","        assign_mask = iou > self.overlap_threshold\n","        if not assign_mask.any():\n","            assign_mask[iou.argmax()] = True\n","        if return_iou:\n","            encoded_box[:, -1][assign_mask] = iou[assign_mask]\n","        assigned_priors = self.priors[assign_mask]\n","        box_center = 0.5 * (box[:2] + box[2:])\n","        box_wh = box[2:] - box[:2]\n","        assigned_priors_center = 0.5 * (assigned_priors[:, :2] +\n","                                        assigned_priors[:, 2:4])\n","        assigned_priors_wh = (assigned_priors[:, 2:4] -\n","                              assigned_priors[:, :2])\n","        # we encode variance\n","        encoded_box[:, :2][assign_mask] = box_center - assigned_priors_center\n","        encoded_box[:, :2][assign_mask] /= assigned_priors_wh\n","        encoded_box[:, :2][assign_mask] /= assigned_priors[:, -4:-2]\n","        encoded_box[:, 2:4][assign_mask] = np.log(box_wh /\n","                                                  assigned_priors_wh)\n","        encoded_box[:, 2:4][assign_mask] /= assigned_priors[:, -2:]\n","        return encoded_box.ravel()\n","\n","    def assign_boxes(self, boxes):\n","        \"\"\"Assign boxes to priors for training.\n","        # Arguments\n","            boxes: Box, numpy tensor of shape (num_boxes, 4 + num_classes),\n","                num_classes without background.\n","        # Return\n","            assignment: Tensor with assigned boxes,\n","                numpy tensor of shape (num_boxes, 4 + num_classes + 8),\n","                priors in ground truth are fictitious,\n","                assignment[:, -8] has 1 if prior should be penalized\n","                    or in other words is assigned to some ground truth box,\n","                assignment[:, -7:] are all 0. See loss for more details.\n","        \"\"\"\n","        assignment = np.zeros((self.num_priors, 4 + self.num_classes + 8))\n","        assignment[:, 4] = 1.0\n","        if len(boxes) == 0:\n","            return assignment\n","        encoded_boxes = np.apply_along_axis(self.encode_box, 1, boxes[:, :4])\n","        encoded_boxes = encoded_boxes.reshape(-1, self.num_priors, 5)\n","        best_iou = encoded_boxes[:, :, -1].max(axis=0)\n","        best_iou_idx = encoded_boxes[:, :, -1].argmax(axis=0)\n","        best_iou_mask = best_iou > 0\n","        best_iou_idx = best_iou_idx[best_iou_mask]\n","        assign_num = len(best_iou_idx)\n","        encoded_boxes = encoded_boxes[:, best_iou_mask, :]\n","        assignment[:, :4][best_iou_mask] = encoded_boxes[best_iou_idx,\n","                                                         np.arange(assign_num),\n","                                                         :4]\n","        assignment[:, 4][best_iou_mask] = 0\n","        assignment[:, 5:-8][best_iou_mask] = boxes[best_iou_idx, 4:]\n","        assignment[:, -8][best_iou_mask] = 1\n","        return assignment\n","\n","    def decode_boxes(self, mbox_loc, mbox_priorbox, variances):\n","        \"\"\"Convert bboxes from local predictions to shifted priors.\n","        # Arguments\n","            mbox_loc: Numpy array of predicted locations.\n","            mbox_priorbox: Numpy array of prior boxes.\n","            variances: Numpy array of variances.\n","        # Return\n","            decode_bbox: Shifted priors.\n","        \"\"\"\n","        prior_width = mbox_priorbox[:, 2] - mbox_priorbox[:, 0]\n","        prior_height = mbox_priorbox[:, 3] - mbox_priorbox[:, 1]\n","        prior_center_x = 0.5 * (mbox_priorbox[:, 2] + mbox_priorbox[:, 0])\n","        prior_center_y = 0.5 * (mbox_priorbox[:, 3] + mbox_priorbox[:, 1])\n","        decode_bbox_center_x = mbox_loc[:, 0] * prior_width * variances[:, 0]\n","        decode_bbox_center_x += prior_center_x\n","        decode_bbox_center_y = mbox_loc[:, 1] * prior_width * variances[:, 1]\n","        decode_bbox_center_y += prior_center_y\n","        decode_bbox_width = np.exp(mbox_loc[:, 2] * variances[:, 2])\n","        decode_bbox_width *= prior_width\n","        decode_bbox_height = np.exp(mbox_loc[:, 3] * variances[:, 3])\n","        decode_bbox_height *= prior_height\n","        decode_bbox_xmin = decode_bbox_center_x - 0.5 * decode_bbox_width\n","        decode_bbox_ymin = decode_bbox_center_y - 0.5 * decode_bbox_height\n","        decode_bbox_xmax = decode_bbox_center_x + 0.5 * decode_bbox_width\n","        decode_bbox_ymax = decode_bbox_center_y + 0.5 * decode_bbox_height\n","        decode_bbox = np.concatenate((decode_bbox_xmin[:, None],\n","                                      decode_bbox_ymin[:, None],\n","                                      decode_bbox_xmax[:, None],\n","                                      decode_bbox_ymax[:, None]), axis=-1)\n","        decode_bbox = np.minimum(np.maximum(decode_bbox, 0.0), 1.0)\n","        return decode_bbox\n","\n","    def detection_out(self, predictions, background_label_id=0, keep_top_k=200,\n","                      confidence_threshold=0.01):\n","        \"\"\"Do non maximum suppression (nms) on prediction results.\n","        # Arguments\n","            predictions: Numpy array of predicted values.\n","            num_classes: Number of classes for prediction.\n","            background_label_id: Label of background class.\n","            keep_top_k: Number of total bboxes to be kept per image\n","                after nms step.\n","            confidence_threshold: Only consider detections,\n","                whose confidences are larger than a threshold.\n","        # Return\n","            results: List of predictions for every picture. Each prediction is:\n","                [label, confidence, xmin, ymin, xmax, ymax]\n","        \"\"\"\n","        mbox_loc = predictions[:, :, :4]\n","        variances = predictions[:, :, -4:]\n","        mbox_priorbox = predictions[:, :, -8:-4]\n","        mbox_conf = predictions[:, :, 4:-8]\n","        results = []\n","        for i in range(len(mbox_loc)):\n","            results.append([])\n","            decode_bbox = self.decode_boxes(mbox_loc[i],\n","                                            mbox_priorbox[i], variances[i])\n","            for c in range(self.num_classes):\n","                if c == background_label_id:\n","                    continue\n","                c_confs = mbox_conf[i, :, c]\n","                c_confs_m = c_confs > confidence_threshold\n","                if len(c_confs[c_confs_m]) > 0:\n","                    boxes_to_process = decode_bbox[c_confs_m]\n","                    confs_to_process = c_confs[c_confs_m]\n","                    feed_dict = {self.boxes: boxes_to_process,\n","                                 self.scores: confs_to_process}\n","                    idx = self.sess.run(self.nms, feed_dict=feed_dict)\n","                    good_boxes = boxes_to_process[idx]\n","                    confs = confs_to_process[idx][:, None]\n","                    labels = c * np.ones((len(idx), 1))\n","                    c_pred = np.concatenate((labels, confs, good_boxes),\n","                                            axis=1)\n","                    results[-1].extend(c_pred)\n","            if len(results[-1]) > 0:\n","                results[-1] = np.array(results[-1])\n","                argsort = np.argsort(results[-1][:, 1])[::-1]\n","                results[-1] = results[-1][argsort]\n","                results[-1] = results[-1][:keep_top_k]\n","        return results"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ANYmYZEoA8Md","colab_type":"code","colab":{}},"cell_type":"code","source":["\"\"\"Some special pupropse layers for SSD.\"\"\"\n","\n","import keras.backend as K\n","from keras.engine.topology import InputSpec\n","from keras.engine.topology import Layer\n","import numpy as np\n","import tensorflow as tf\n","\n","\n","class Normalize(Layer):\n","    \"\"\"Normalization layer as described in ParseNet paper.\n","    # Arguments\n","        scale: Default feature scale.\n","    # Input shape\n","        4D tensor with shape:\n","        `(samples, channels, rows, cols)` if dim_ordering='th'\n","        or 4D tensor with shape:\n","        `(samples, rows, cols, channels)` if dim_ordering='tf'.\n","    # Output shape\n","        Same as input\n","    # References\n","        http://cs.unc.edu/~wliu/papers/parsenet.pdf\n","    #TODO\n","        Add possibility to have one scale for all features.\n","    \"\"\"\n","    def __init__(self, scale, **kwargs):\n","        if K.image_dim_ordering() == 'tf':\n","            self.axis = 3\n","        else:\n","            self.axis = 1\n","        self.scale = scale\n","        super(Normalize, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        self.input_spec = [InputSpec(shape=input_shape)]\n","        shape = (input_shape[self.axis],)\n","        init_gamma = self.scale * np.ones(shape)\n","        self.gamma = K.variable(init_gamma, name='{}_gamma'.format(self.name))\n","        self.trainable_weights = [self.gamma]\n","\n","    def call(self, x, mask=None):\n","        output = K.l2_normalize(x, self.axis)\n","        output *= self.gamma\n","        return output\n","\n","\n","class PriorBox(Layer):\n","    \"\"\"Generate the prior boxes of designated sizes and aspect ratios.\n","    # Arguments\n","        img_size: Size of the input image as tuple (w, h).\n","        min_size: Minimum box size in pixels.\n","        max_size: Maximum box size in pixels.\n","        aspect_ratios: List of aspect ratios of boxes.\n","        flip: Whether to consider reverse aspect ratios.\n","        variances: List of variances for x, y, w, h.\n","        clip: Whether to clip the prior's coordinates\n","            such that they are within [0, 1].\n","    # Input shape\n","        4D tensor with shape:\n","        `(samples, channels, rows, cols)` if dim_ordering='th'\n","        or 4D tensor with shape:\n","        `(samples, rows, cols, channels)` if dim_ordering='tf'.\n","    # Output shape\n","        3D tensor with shape:\n","        (samples, num_boxes, 8)\n","    # References\n","        https://arxiv.org/abs/1512.02325\n","    #TODO\n","        Add possibility not to have variances.\n","        Add Theano support\n","    \"\"\"\n","    def __init__(self, img_size, min_size, max_size=None, aspect_ratios=None,\n","                 flip=True, variances=[0.1], clip=True, **kwargs):\n","        if K.image_dim_ordering() == 'tf':\n","            self.waxis = 2\n","            self.haxis = 1\n","        else:\n","            self.waxis = 3\n","            self.haxis = 2\n","        self.img_size = img_size\n","        if min_size <= 0:\n","            raise Exception('min_size must be positive.')\n","        self.min_size = min_size\n","        self.max_size = max_size\n","        self.aspect_ratios = [1.0]\n","        if max_size:\n","            if max_size < min_size:\n","                raise Exception('max_size must be greater than min_size.')\n","            self.aspect_ratios.append(1.0)\n","        if aspect_ratios:\n","            for ar in aspect_ratios:\n","                if ar in self.aspect_ratios:\n","                    continue\n","                self.aspect_ratios.append(ar)\n","                if flip:\n","                    self.aspect_ratios.append(1.0 / ar)\n","        self.variances = np.array(variances)\n","        self.clip = True\n","        super(PriorBox, self).__init__(**kwargs)\n","\n","    def get_output_shape_for(self, input_shape):\n","        num_priors_ = len(self.aspect_ratios)\n","        layer_width = input_shape[self.waxis]\n","        layer_height = input_shape[self.haxis]\n","        num_boxes = num_priors_ * layer_width * layer_height\n","        return (input_shape[0], num_boxes, 8)\n","\n","    def call(self, x, mask=None):\n","        if hasattr(x, '_keras_shape'):\n","            input_shape = x._keras_shape\n","        elif hasattr(K, 'int_shape'):\n","            input_shape = K.int_shape(x)\n","        layer_width = input_shape[self.waxis]\n","        layer_height = input_shape[self.haxis]\n","        img_width = self.img_size[0]\n","        img_height = self.img_size[1]\n","        # define prior boxes shapes\n","        box_widths = []\n","        box_heights = []\n","        for ar in self.aspect_ratios:\n","            if ar == 1 and len(box_widths) == 0:\n","                box_widths.append(self.min_size)\n","                box_heights.append(self.min_size)\n","            elif ar == 1 and len(box_widths) > 0:\n","                box_widths.append(np.sqrt(self.min_size * self.max_size))\n","                box_heights.append(np.sqrt(self.min_size * self.max_size))\n","            elif ar != 1:\n","                box_widths.append(self.min_size * np.sqrt(ar))\n","                box_heights.append(self.min_size / np.sqrt(ar))\n","        box_widths = 0.5 * np.array(box_widths)\n","        box_heights = 0.5 * np.array(box_heights)\n","        # define centers of prior boxes\n","        step_x = img_width / layer_width\n","        step_y = img_height / layer_height\n","        linx = np.linspace(0.5 * step_x, img_width - 0.5 * step_x,\n","                           layer_width)\n","        liny = np.linspace(0.5 * step_y, img_height - 0.5 * step_y,\n","                           layer_height)\n","        centers_x, centers_y = np.meshgrid(linx, liny)\n","        centers_x = centers_x.reshape(-1, 1)\n","        centers_y = centers_y.reshape(-1, 1)\n","        # define xmin, ymin, xmax, ymax of prior boxes\n","        num_priors_ = len(self.aspect_ratios)\n","        prior_boxes = np.concatenate((centers_x, centers_y), axis=1)\n","        prior_boxes = np.tile(prior_boxes, (1, 2 * num_priors_))\n","        prior_boxes[:, ::4] -= box_widths\n","        prior_boxes[:, 1::4] -= box_heights\n","        prior_boxes[:, 2::4] += box_widths\n","        prior_boxes[:, 3::4] += box_heights\n","        prior_boxes[:, ::2] /= img_width\n","        prior_boxes[:, 1::2] /= img_height\n","        prior_boxes = prior_boxes.reshape(-1, 4)\n","        if self.clip:\n","            prior_boxes = np.minimum(np.maximum(prior_boxes, 0.0), 1.0)\n","        # define variances\n","        num_boxes = len(prior_boxes)\n","        if len(self.variances) == 1:\n","            variances = np.ones((num_boxes, 4)) * self.variances[0]\n","        elif len(self.variances) == 4:\n","            variances = np.tile(self.variances, (num_boxes, 1))\n","        else:\n","            raise Exception('Must provide one or four variances.')\n","        prior_boxes = np.concatenate((prior_boxes, variances), axis=1)\n","        prior_boxes_tensor = K.expand_dims(K.variable(prior_boxes), 0)\n","        if K.backend() == 'tensorflow':\n","            pattern = [tf.shape(x)[0], 1, 1]\n","            prior_boxes_tensor = tf.tile(prior_boxes_tensor, pattern)\n","        elif K.backend() == 'theano':\n","            #TODO\n","            pass\n","        return prior_boxes_tensor"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EgNK0urG_sVa","colab_type":"code","colab":{}},"cell_type":"code","source":["import keras.backend as K\n","from keras.layers import Activation\n","from keras.layers import AtrousConvolution2D\n","from keras.layers import Convolution2D\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.layers import GlobalAveragePooling2D\n","from keras.layers import Input\n","from keras.layers import MaxPooling2D\n","from keras.layers import merge\n","from keras.layers import Reshape\n","from keras.layers import ZeroPadding2D\n","from keras.models import Model\n","\n","#from ssd_layers import Normalize\n","#from ssd_layers import PriorBox"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zwewNPSN_0pD","colab_type":"code","colab":{}},"cell_type":"code","source":["def SSD300(input_shape, num_classes=21):\n","    \"\"\"SSD300 architecture.\n","    # Arguments\n","        input_shape: Shape of the input image,\n","            expected to be either (300, 300, 3) or (3, 300, 300)(not tested).\n","        num_classes: Number of classes including background.\n","    # References\n","        https://arxiv.org/abs/1512.02325\n","    \"\"\"\n","    net = {}\n","    # Block 1\n","    input_tensor = input_tensor = Input(shape=input_shape)\n","    img_size = (input_shape[1], input_shape[0])\n","    net['input'] = input_tensor\n","    net['conv1_1'] = Convolution2D(64, 3, 3,\n","                                   activation='relu',\n","                                   border_mode='same',\n","                                   name='conv1_1')(net['input'])\n","    net['conv1_2'] = Convolution2D(64, 3, 3,\n","                                   activation='relu',\n","                                   border_mode='same',\n","                                   name='conv1_2')(net['conv1_1'])\n","    net['pool1'] = MaxPooling2D((2, 2), strides=(2, 2), border_mode='same',\n","                                name='pool1')(net['conv1_2'])\n","    # Block 2\n","    net['conv2_1'] = Convolution2D(128, 3, 3,\n","                                   activation='relu',\n","                                   border_mode='same',\n","                                   name='conv2_1')(net['pool1'])\n","    net['conv2_2'] = Convolution2D(128, 3, 3,\n","                                   activation='relu',\n","                                   border_mode='same',\n","                                   name='conv2_2')(net['conv2_1'])\n","    net['pool2'] = MaxPooling2D((2, 2), strides=(2, 2), border_mode='same',\n","                                name='pool2')(net['conv2_2'])\n","    # Block 3\n","    net['conv3_1'] = Convolution2D(256, 3, 3,\n","                                   activation='relu',\n","                                   border_mode='same',\n","                                   name='conv3_1')(net['pool2'])\n","    net['conv3_2'] = Convolution2D(256, 3, 3,\n","                                   activation='relu',\n","                                   border_mode='same',\n","                                   name='conv3_2')(net['conv3_1'])\n","    net['conv3_3'] = Convolution2D(256, 3, 3,\n","                                   activation='relu',\n","                                   border_mode='same',\n","                                   name='conv3_3')(net['conv3_2'])\n","    net['pool3'] = MaxPooling2D((2, 2), strides=(2, 2), border_mode='same',\n","                                name='pool3')(net['conv3_3'])\n","    # Block 4\n","    net['conv4_1'] = Convolution2D(512, 3, 3,\n","                                   activation='relu',\n","                                   border_mode='same',\n","                                   name='conv4_1')(net['pool3'])\n","    net['conv4_2'] = Convolution2D(512, 3, 3,\n","                                   activation='relu',\n","                                   border_mode='same',\n","                                   name='conv4_2')(net['conv4_1'])\n","    net['conv4_3'] = Convolution2D(512, 3, 3,\n","                                   activation='relu',\n","                                   border_mode='same',\n","                                   name='conv4_3')(net['conv4_2'])\n","    net['pool4'] = MaxPooling2D((2, 2), strides=(2, 2), border_mode='same',\n","                                name='pool4')(net['conv4_3'])\n","    # Block 5\n","    net['conv5_1'] = Convolution2D(512, 3, 3,\n","                                   activation='relu',\n","                                   border_mode='same',\n","                                   name='conv5_1')(net['pool4'])\n","    net['conv5_2'] = Convolution2D(512, 3, 3,\n","                                   activation='relu',\n","                                   border_mode='same',\n","                                   name='conv5_2')(net['conv5_1'])\n","    net['conv5_3'] = Convolution2D(512, 3, 3,\n","                                   activation='relu',\n","                                   border_mode='same',\n","                                   name='conv5_3')(net['conv5_2'])\n","    net['pool5'] = MaxPooling2D((3, 3), strides=(1, 1), border_mode='same',\n","                                name='pool5')(net['conv5_3'])\n","    # FC6\n","    net['fc6'] = AtrousConvolution2D(1024, 3, 3, atrous_rate=(6, 6),\n","                                     activation='relu', border_mode='same',\n","                                     name='fc6')(net['pool5'])\n","    # x = Dropout(0.5, name='drop6')(x)\n","    # FC7\n","    net['fc7'] = Convolution2D(1024, 1, 1, activation='relu',\n","                               border_mode='same', name='fc7')(net['fc6'])\n","    # x = Dropout(0.5, name='drop7')(x)\n","    # Block 6\n","    net['conv6_1'] = Convolution2D(256, 1, 1, activation='relu',\n","                                   border_mode='same',\n","                                   name='conv6_1')(net['fc7'])\n","    net['conv6_2'] = Convolution2D(512, 3, 3, subsample=(2, 2),\n","                                   activation='relu', border_mode='same',\n","                                   name='conv6_2')(net['conv6_1'])\n","    # Block 7\n","    net['conv7_1'] = Convolution2D(128, 1, 1, activation='relu',\n","                                   border_mode='same',\n","                                   name='conv7_1')(net['conv6_2'])\n","    net['conv7_2'] = ZeroPadding2D()(net['conv7_1'])\n","    net['conv7_2'] = Convolution2D(256, 3, 3, subsample=(2, 2),\n","                                   activation='relu', border_mode='valid',\n","                                   name='conv7_2')(net['conv7_2'])\n","    # Block 8\n","    net['conv8_1'] = Convolution2D(128, 1, 1, activation='relu',\n","                                   border_mode='same',\n","                                   name='conv8_1')(net['conv7_2'])\n","    net['conv8_2'] = Convolution2D(256, 3, 3, subsample=(2, 2),\n","                                   activation='relu', border_mode='same',\n","                                   name='conv8_2')(net['conv8_1'])\n","    # Last Pool\n","    net['pool6'] = GlobalAveragePooling2D(name='pool6')(net['conv8_2'])\n","    # Prediction from conv4_3\n","    net['conv4_3_norm'] = Normalize(20, name='conv4_3_norm')(net['conv4_3'])\n","    num_priors = 3\n","    x = Convolution2D(num_priors * 4, 3, 3, border_mode='same',\n","                      name='conv4_3_norm_mbox_loc')(net['conv4_3_norm'])\n","    net['conv4_3_norm_mbox_loc'] = x\n","    flatten = Flatten(name='conv4_3_norm_mbox_loc_flat')\n","    net['conv4_3_norm_mbox_loc_flat'] = flatten(net['conv4_3_norm_mbox_loc'])\n","    name = 'conv4_3_norm_mbox_conf'\n","    if num_classes != 21:\n","        name += '_{}'.format(num_classes)\n","    x = Convolution2D(num_priors * num_classes, 3, 3, border_mode='same',\n","                      name=name)(net['conv4_3_norm'])\n","    net['conv4_3_norm_mbox_conf'] = x\n","    flatten = Flatten(name='conv4_3_norm_mbox_conf_flat')\n","    net['conv4_3_norm_mbox_conf_flat'] = flatten(net['conv4_3_norm_mbox_conf'])\n","    priorbox = PriorBox(img_size, 30.0, aspect_ratios=[2],\n","                        variances=[0.1, 0.1, 0.2, 0.2],\n","                        name='conv4_3_norm_mbox_priorbox')\n","    net['conv4_3_norm_mbox_priorbox'] = priorbox(net['conv4_3_norm'])\n","    # Prediction from fc7\n","    num_priors = 6\n","    net['fc7_mbox_loc'] = Convolution2D(num_priors * 4, 3, 3,\n","                                        border_mode='same',\n","                                        name='fc7_mbox_loc')(net['fc7'])\n","    flatten = Flatten(name='fc7_mbox_loc_flat')\n","    net['fc7_mbox_loc_flat'] = flatten(net['fc7_mbox_loc'])\n","    name = 'fc7_mbox_conf'\n","    if num_classes != 21:\n","        name += '_{}'.format(num_classes)\n","    net['fc7_mbox_conf'] = Convolution2D(num_priors * num_classes, 3, 3,\n","                                         border_mode='same',\n","                                         name=name)(net['fc7'])\n","    flatten = Flatten(name='fc7_mbox_conf_flat')\n","    net['fc7_mbox_conf_flat'] = flatten(net['fc7_mbox_conf'])\n","    priorbox = PriorBox(img_size, 60.0, max_size=114.0, aspect_ratios=[2, 3],\n","                        variances=[0.1, 0.1, 0.2, 0.2],\n","                        name='fc7_mbox_priorbox')\n","    net['fc7_mbox_priorbox'] = priorbox(net['fc7'])\n","    # Prediction from conv6_2\n","    num_priors = 6\n","    x = Convolution2D(num_priors * 4, 3, 3, border_mode='same',\n","                      name='conv6_2_mbox_loc')(net['conv6_2'])\n","    net['conv6_2_mbox_loc'] = x\n","    flatten = Flatten(name='conv6_2_mbox_loc_flat')\n","    net['conv6_2_mbox_loc_flat'] = flatten(net['conv6_2_mbox_loc'])\n","    name = 'conv6_2_mbox_conf'\n","    if num_classes != 21:\n","        name += '_{}'.format(num_classes)\n","    x = Convolution2D(num_priors * num_classes, 3, 3, border_mode='same',\n","                      name=name)(net['conv6_2'])\n","    net['conv6_2_mbox_conf'] = x\n","    flatten = Flatten(name='conv6_2_mbox_conf_flat')\n","    net['conv6_2_mbox_conf_flat'] = flatten(net['conv6_2_mbox_conf'])\n","    priorbox = PriorBox(img_size, 114.0, max_size=168.0, aspect_ratios=[2, 3],\n","                        variances=[0.1, 0.1, 0.2, 0.2],\n","                        name='conv6_2_mbox_priorbox')\n","    net['conv6_2_mbox_priorbox'] = priorbox(net['conv6_2'])\n","    # Prediction from conv7_2\n","    num_priors = 6\n","    x = Convolution2D(num_priors * 4, 3, 3, border_mode='same',\n","                      name='conv7_2_mbox_loc')(net['conv7_2'])\n","    net['conv7_2_mbox_loc'] = x\n","    flatten = Flatten(name='conv7_2_mbox_loc_flat')\n","    net['conv7_2_mbox_loc_flat'] = flatten(net['conv7_2_mbox_loc'])\n","    name = 'conv7_2_mbox_conf'\n","    if num_classes != 21:\n","        name += '_{}'.format(num_classes)\n","    x = Convolution2D(num_priors * num_classes, 3, 3, border_mode='same',\n","                      name=name)(net['conv7_2'])\n","    net['conv7_2_mbox_conf'] = x\n","    flatten = Flatten(name='conv7_2_mbox_conf_flat')\n","    net['conv7_2_mbox_conf_flat'] = flatten(net['conv7_2_mbox_conf'])\n","    priorbox = PriorBox(img_size, 168.0, max_size=222.0, aspect_ratios=[2, 3],\n","                        variances=[0.1, 0.1, 0.2, 0.2],\n","                        name='conv7_2_mbox_priorbox')\n","    net['conv7_2_mbox_priorbox'] = priorbox(net['conv7_2'])\n","    # Prediction from conv8_2\n","    num_priors = 6\n","    x = Convolution2D(num_priors * 4, 3, 3, border_mode='same',\n","                      name='conv8_2_mbox_loc')(net['conv8_2'])\n","    net['conv8_2_mbox_loc'] = x\n","    flatten = Flatten(name='conv8_2_mbox_loc_flat')\n","    net['conv8_2_mbox_loc_flat'] = flatten(net['conv8_2_mbox_loc'])\n","    name = 'conv8_2_mbox_conf'\n","    if num_classes != 21:\n","        name += '_{}'.format(num_classes)\n","    x = Convolution2D(num_priors * num_classes, 3, 3, border_mode='same',\n","                      name=name)(net['conv8_2'])\n","    net['conv8_2_mbox_conf'] = x\n","    flatten = Flatten(name='conv8_2_mbox_conf_flat')\n","    net['conv8_2_mbox_conf_flat'] = flatten(net['conv8_2_mbox_conf'])\n","    priorbox = PriorBox(img_size, 222.0, max_size=276.0, aspect_ratios=[2, 3],\n","                        variances=[0.1, 0.1, 0.2, 0.2],\n","                        name='conv8_2_mbox_priorbox')\n","    net['conv8_2_mbox_priorbox'] = priorbox(net['conv8_2'])\n","    # Prediction from pool6\n","    num_priors = 6\n","    x = Dense(num_priors * 4, name='pool6_mbox_loc_flat')(net['pool6'])\n","    net['pool6_mbox_loc_flat'] = x\n","    name = 'pool6_mbox_conf_flat'\n","    if num_classes != 21:\n","        name += '_{}'.format(num_classes)\n","    x = Dense(num_priors * num_classes, name=name)(net['pool6'])\n","    net['pool6_mbox_conf_flat'] = x\n","    priorbox = PriorBox(img_size, 276.0, max_size=330.0, aspect_ratios=[2, 3],\n","                        variances=[0.1, 0.1, 0.2, 0.2],\n","                        name='pool6_mbox_priorbox')\n","    if K.image_dim_ordering() == 'tf':\n","        target_shape = (1, 1, 256)\n","    else:\n","        target_shape = (256, 1, 1)\n","    net['pool6_reshaped'] = Reshape(target_shape,\n","                                    name='pool6_reshaped')(net['pool6'])\n","    net['pool6_mbox_priorbox'] = priorbox(net['pool6_reshaped'])\n","    # Gather all predictions\n","    net['mbox_loc'] = merge([net['conv4_3_norm_mbox_loc_flat'],\n","                             net['fc7_mbox_loc_flat'],\n","                             net['conv6_2_mbox_loc_flat'],\n","                             net['conv7_2_mbox_loc_flat'],\n","                             net['conv8_2_mbox_loc_flat'],\n","                             net['pool6_mbox_loc_flat']],\n","                            mode='concat', concat_axis=1, name='mbox_loc')\n","    net['mbox_conf'] = merge([net['conv4_3_norm_mbox_conf_flat'],\n","                              net['fc7_mbox_conf_flat'],\n","                              net['conv6_2_mbox_conf_flat'],\n","                              net['conv7_2_mbox_conf_flat'],\n","                              net['conv8_2_mbox_conf_flat'],\n","                              net['pool6_mbox_conf_flat']],\n","                             mode='concat', concat_axis=1, name='mbox_conf')\n","    net['mbox_priorbox'] = merge([net['conv4_3_norm_mbox_priorbox'],\n","                                  net['fc7_mbox_priorbox'],\n","                                  net['conv6_2_mbox_priorbox'],\n","                                  net['conv7_2_mbox_priorbox'],\n","                                  net['conv8_2_mbox_priorbox'],\n","                                  net['pool6_mbox_priorbox']],\n","                                 mode='concat', concat_axis=1,\n","                                 name='mbox_priorbox')\n","    if hasattr(net['mbox_loc'], '_keras_shape'):\n","        num_boxes = net['mbox_loc']._keras_shape[-1] // 4\n","    elif hasattr(net['mbox_loc'], 'int_shape'):\n","        num_boxes = K.int_shape(net['mbox_loc'])[-1] // 4\n","    net['mbox_loc'] = Reshape((num_boxes, 4),\n","                              name='mbox_loc_final')(net['mbox_loc'])\n","    net['mbox_conf'] = Reshape((num_boxes, num_classes),\n","                               name='mbox_conf_logits')(net['mbox_conf'])\n","    net['mbox_conf'] = Activation('softmax',\n","                                  name='mbox_conf_final')(net['mbox_conf'])\n","    net['predictions'] = merge([net['mbox_loc'],\n","                               net['mbox_conf'],\n","                               net['mbox_priorbox']],\n","                               mode='concat', concat_axis=2,\n","                               name='predictions')\n","    model = Model(net['input'], net['predictions'])\n","    return model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IJgIElKH960P","colab_type":"code","colab":{}},"cell_type":"code","source":["import cv2\n","import keras\n","from keras.applications.imagenet_utils import preprocess_input\n","from keras.backend.tensorflow_backend import set_session\n","from keras.models import Model\n","from keras.preprocessing import image\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from scipy.misc import imread\n","import tensorflow as tf\n","\n","#from ssd import SSD300\n","#from ssd_utils import BBoxUtility"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4qHegniW93C1","colab_type":"code","colab":{}},"cell_type":"code","source":["%matplotlib inline\n","plt.rcParams['figure.figsize'] = (8, 8)\n","plt.rcParams['image.interpolation'] = 'nearest'\n","\n","np.set_printoptions(suppress=True)\n","\n","config = tf.ConfigProto()\n","config.gpu_options.per_process_gpu_memory_fraction = 0.45\n","set_session(tf.Session(config=config))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xVZ5pHJqALN0","colab_type":"code","colab":{}},"cell_type":"code","source":["voc_classes = ['Aeroplane', 'Bicycle', 'Bird', 'Boat', 'Bottle',\n","               'Bus', 'Car', 'Cat', 'Chair', 'Cow', 'Diningtable',\n","               'Dog', 'Horse','Motorbike', 'Person', 'Pottedplant',\n","               'Sheep', 'Sofa', 'Train', 'Tvmonitor']\n","NUM_CLASSES = len(voc_classes) + 1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ripYOmVTAku4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1538},"outputId":"0f1f5ea6-d1b7-41b2-acf9-fd27197b9fb4","executionInfo":{"status":"error","timestamp":1538470969387,"user_tz":-540,"elapsed":1244,"user":{"displayName":"nori 86","photoUrl":"","userId":"17990641330801160498"}}},"cell_type":"code","source":["input_shape=(300, 300, 3)\n","model = SSD300(input_shape, num_classes=NUM_CLASSES)\n","model.load_weights('weights_SSD300.hdf5', by_name=True)\n","bbox_util = BBoxUtility(NUM_CLASSES)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", name=\"conv1_1\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", name=\"conv1_2\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), strides=(2, 2), name=\"pool1\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", name=\"conv2_1\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", name=\"conv2_2\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), strides=(2, 2), name=\"pool2\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"conv3_1\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"conv3_2\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"conv3_3\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), strides=(2, 2), name=\"pool3\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:55: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv4_1\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv4_2\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:63: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv4_3\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:65: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), strides=(2, 2), name=\"pool4\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv5_1\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:74: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv5_2\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:78: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv5_3\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:80: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((3, 3), strides=(1, 1), name=\"pool5\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/keras/legacy/layers.py:762: UserWarning: The `AtrousConvolution2D` layer  has been deprecated. Use instead the `Conv2D` layer with the `dilation_rate` argument.\n","  warnings.warn('The `AtrousConvolution2D` layer '\n","/usr/local/lib/python3.6/dist-packages/keras/legacy/layers.py:766: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (3, 3), activation=\"relu\", name=\"fc6\", dilation_rate=(6, 6), padding=\"same\")`\n","  return Conv2D(*args, **kwargs)\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:88: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), activation=\"relu\", name=\"fc7\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:93: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), activation=\"relu\", name=\"conv6_1\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:96: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", name=\"conv6_2\", strides=(2, 2), padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), activation=\"relu\", name=\"conv7_1\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:104: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"conv7_2\", strides=(2, 2), padding=\"valid\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:108: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), activation=\"relu\", name=\"conv8_1\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:111: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", name=\"conv8_2\", strides=(2, 2), padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:118: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), name=\"conv4_3_norm_mbox_loc\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:126: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(63, (3, 3), name=\"conv4_3_norm_mbox_conf\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py:638: UserWarning: Class `__main__.PriorBox` defines `get_output_shape_for` but does not override `compute_output_shape`. If this is a Keras 1 layer, please implement `compute_output_shape` to support Keras 2.\n","  output_shape = self.compute_output_shape(input_shape)\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:138: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), name=\"fc7_mbox_loc\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:146: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(126, (3, 3), name=\"fc7_mbox_conf\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:156: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), name=\"conv6_2_mbox_loc\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:164: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(126, (3, 3), name=\"conv6_2_mbox_conf\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:175: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), name=\"conv7_2_mbox_loc\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:183: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(126, (3, 3), name=\"conv7_2_mbox_conf\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:194: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), name=\"conv8_2_mbox_loc\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:202: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(126, (3, 3), name=\"conv8_2_mbox_conf\", padding=\"same\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:236: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n","/usr/local/lib/python3.6/dist-packages/keras/legacy/layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n","  name=name)\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:243: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:251: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"],"name":"stderr"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-dd64fe36fa33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSSD300\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weights_SSD300.hdf5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbbox_util\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBBoxUtility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-a0b6c615682d>\u001b[0m in \u001b[0;36mSSD300\u001b[0;34m(input_shape, num_classes)\u001b[0m\n\u001b[1;32m    249\u001b[0m                                   net['pool6_mbox_priorbox']],\n\u001b[1;32m    250\u001b[0m                                  \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'concat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                                  name='mbox_priorbox')\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mbox_loc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mnum_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mbox_loc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/layers.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(inputs, mode, concat_axis, dot_axes, output_shape, output_mask, arguments, name)\u001b[0m\n\u001b[1;32m    463\u001b[0m                             \u001b[0mnode_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m                             \u001b[0mtensor_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m                             name=name)\n\u001b[0m\u001b[1;32m    466\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmerge_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/layers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, mode, concat_axis, dot_axes, output_shape, output_mask, arguments, node_indices, tensor_indices, name)\u001b[0m\n\u001b[1;32m    116\u001b[0m             self._arguments_validation(layers, mode,\n\u001b[1;32m    117\u001b[0m                                        \u001b[0mconcat_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdot_axes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                                        node_indices, tensor_indices)\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0minput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/layers.py\u001b[0m in \u001b[0;36m_arguments_validation\u001b[0;34m(self, layers, mode, concat_axis, dot_axes, node_indices, tensor_indices)\u001b[0m\n\u001b[1;32m    196\u001b[0m                                  \u001b[0;34m'layers with matching '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                                  \u001b[0;34m'output shapes except for the concat axis. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m                                  'Layer shapes: %s' % (input_shapes))\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: \"concat\" mode can only merge layers with matching output shapes except for the concat axis. Layer shapes: [(None, 38, 38, 512), (None, 19, 19, 1024), (None, 10, 10, 512), (None, 5, 5, 256), (None, 3, 3, 256), (None, 1, 1, 256)]"]}]},{"metadata":{"id":"M7bh2J8kAqXW","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"8_hINIkJB2SI","colab_type":"code","colab":{}},"cell_type":"code","source":["!git clone "],"execution_count":0,"outputs":[]}]}